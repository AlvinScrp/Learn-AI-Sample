import fs from 'fs';
import path from 'path';
import { fileURLToPath } from 'url';

// è·å–å½“å‰æ–‡ä»¶çš„ç›®å½•
const __filename = fileURLToPath(import.meta.url);
const __dirname = path.dirname(__filename);

// åœç”¨è¯åˆ—è¡¨
const STOP_WORDS = ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', "you're", "you've", "you'll", "you'd", 'your',
    'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', "she's", 'her', 'hers', 'herself', 'it',
    "it's", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this',
    'that', "that'll", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had',
    'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while',
    'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above',
    'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once',
    'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some',
    'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don',
    "don't", 'should', "should've", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', "aren't", 'couldn',
    "couldn't", 'didn', "didn't", 'doesn', "doesn't", 'hadn', "hadn't", 'hasn', "hasn't", 'haven', "haven't", 'isn',
    "isn't", 'ma', 'mightn', "mightn't", 'mustn', "mustn't", 'needn', "needn't", 'shan', "shan't", 'shouldn', "shouldn't",
    'wasn', "wasn't", 'weren', "weren't", 'won', "won't", 'wouldn', "wouldn't"];

/**
 * æ¸…ç†æ–‡æœ¬
 * @param {string} text - è¾“å…¥æ–‡æœ¬
 * @returns {string} - æ¸…ç†åçš„æ–‡æœ¬
 */
function cleanText(text) {
    return text.toLowerCase() // è½¬æ¢ä¸ºå°å†™
        .replace(/[^\w\s]/g, ' ') // ç§»é™¤æ ‡ç‚¹ç¬¦å·
        .replace(/\s+/g, ' ') // åˆå¹¶å¤šä¸ªç©ºæ ¼
        .trim();
}

/**
 * åˆ†è¯
 * @param {string} text - è¾“å…¥æ–‡æœ¬
 * @returns {Array} - åˆ†è¯ç»“æœ
 */
function tokenize(text) {
    return text.split(/\s+/).filter(word => word.length > 0);
}

/**
 * ç§»é™¤åœç”¨è¯
 * @param {Array} tokens - åˆ†è¯ç»“æœ
 * @returns {Array} - ç§»é™¤åœç”¨è¯åçš„ç»“æœ
 */
function removeStopWords(tokens) {
    return tokens.filter(token => !STOP_WORDS.includes(token.toLowerCase()));
}

/**
 * ç”ŸæˆN-Gram
 * @param {Array} tokens - åˆ†è¯ç»“æœ
 * @param {number} n - N-Gramçš„Nå€¼
 * @returns {Array} - N-Gramç»“æœ
 */
function generateNGrams(tokens, n) {
    const ngrams = [];
    for (let i = 0; i <= tokens.length - n; i++) {
        ngrams.push(tokens.slice(i, i + n).join(' '));
    }
    return ngrams;
}

/**
 * è®¡ç®—è¯é¢‘
 * @param {Array} items - é¡¹ç›®åˆ—è¡¨
 * @returns {Object} - è¯é¢‘ç»Ÿè®¡
 */
function countFrequency(items) {
    const frequency = {};
    items.forEach(item => {
        frequency[item] = (frequency[item] || 0) + 1;
    });
    return frequency;
}

/**
 * æŒ‰é¢‘ç‡æ’åº
 * @param {Object} frequency - è¯é¢‘å¯¹è±¡
 * @returns {Array} - æ’åºåçš„ç»“æœ
 */
function sortByFrequency(frequency) {
    return Object.entries(frequency)
        .map(([item, count]) => ({ item, count }))
        .sort((a, b) => b.count - a.count);
}

/**
 * è§£æCSVè¡Œ
 * @param {string} line - CSVè¡Œ
 * @returns {Array} - è§£æåçš„å­—æ®µ
 */
function parseCSVLine(line) {
    const result = [];
    let current = '';
    let inQuotes = false;
    
    for (let i = 0; i < line.length; i++) {
        const char = line[i];
        if (char === '"') {
            inQuotes = !inQuotes;
        } else if (char === ',' && !inQuotes) {
            result.push(current.trim());
            current = '';
        } else {
            current += char;
        }
    }
    result.push(current.trim());
    return result;
}

/**
 * è¯»å–CSVæ–‡ä»¶
 * @param {string} filePath - æ–‡ä»¶è·¯å¾„
 * @returns {Array} - è§£æåçš„æ•°æ®
 */
function readCSV(filePath) {
    try {
        const content = fs.readFileSync(filePath, 'utf8');
        const lines = content.split('\n').filter(line => line.trim());
        
        if (lines.length < 2) {
            console.error('CSVæ–‡ä»¶æ ¼å¼é”™è¯¯æˆ–ä¸ºç©º');
            return [];
        }
        
        const headers = parseCSVLine(lines[0]);
        const descIndex = headers.findIndex(header => header.trim().toLowerCase() === 'desc');
        
        if (descIndex === -1) {
            console.error('æœªæ‰¾åˆ°descåˆ—');
            return [];
        }
        
        const data = [];
        for (let i = 1; i < lines.length; i++) {
            const values = parseCSVLine(lines[i]);
            if (values[descIndex]) {
                data.push({ desc: values[descIndex].trim() });
            }
        }
        
        return data;
    } catch (error) {
        console.error('è¯»å–CSVæ–‡ä»¶æ—¶å‡ºé”™:', error);
        return [];
    }
}

/**
 * è®¡ç®—TF-IDF
 * @param {Array} documents - æ–‡æ¡£åˆ—è¡¨
 * @returns {Object} - TF-IDFç»“æœ
 */
function calculateTFIDF(documents) {
    const tfidf = {
        documents: [],
        vocabulary: new Set(),
        word_doc_freq: {}, // æ¯ä¸ªè¯å‡ºç°åœ¨å¤šå°‘ä¸ªæ–‡æ¡£ä¸­
        tfidf_matrix: []
    };
    
    // ç¬¬ä¸€æ­¥ï¼šé¢„å¤„ç†æ‰€æœ‰æ–‡æ¡£ï¼Œæ„å»ºè¯æ±‡è¡¨
    documents.forEach((doc, docIndex) => {
        const cleanedText = cleanText(doc.desc);
        const tokens = tokenize(cleanedText);
        const filteredTokens = removeStopWords(tokens);
        
        // æ·»åŠ åˆ°è¯æ±‡è¡¨
        filteredTokens.forEach(token => {
            tfidf.vocabulary.add(token);
        });
        
        // è®¡ç®—è¯é¢‘
        const wordFreq = {};
        filteredTokens.forEach(token => {
            wordFreq[token] = (wordFreq[token] || 0) + 1;
        });
        
        tfidf.documents.push({
            original: doc.desc,
            processed: filteredTokens,
            wordFreq: wordFreq,
            totalWords: filteredTokens.length
        });
    });
    
    // ç¬¬äºŒæ­¥ï¼šè®¡ç®—æ¯ä¸ªè¯å‡ºç°åœ¨å¤šå°‘ä¸ªæ–‡æ¡£ä¸­
    tfidf.vocabulary.forEach(word => {
        let docCount = 0;
        tfidf.documents.forEach(doc => {
            if (doc.wordFreq[word]) {
                docCount++;
            }
        });
        tfidf.word_doc_freq[word] = docCount;
    });
    
    // ç¬¬ä¸‰æ­¥ï¼šè®¡ç®—TF-IDFå€¼
    const N = tfidf.documents.length; // æ€»æ–‡æ¡£æ•°
    
    tfidf.documents.forEach((doc, docIndex) => {
        const docTFIDF = {};
        
        tfidf.vocabulary.forEach(word => {
            if (doc.wordFreq[word]) {
                // TF: è¯åœ¨æ–‡æ¡£ä¸­çš„é¢‘ç‡
                const tf = doc.wordFreq[word] / doc.totalWords;
                
                // IDF: é€†æ–‡æ¡£é¢‘ç‡
                const idf = Math.log(N / tfidf.word_doc_freq[word]);
                
                // TF-IDFå€¼
                docTFIDF[word] = tf * idf;
            } else {
                docTFIDF[word] = 0;
            }
        });
        
        tfidf.tfidf_matrix.push(docTFIDF);
    });
    
    return tfidf;
}

/**
 * è·å–TF-IDFç‰¹å¾å‘é‡
 * @param {Object} tfidf - TF-IDFå¯¹è±¡
 * @returns {Object} - ç‰¹å¾å‘é‡ç»“æœ
 */
function getTFIDFFeatures(tfidf) {
    const features = {
        vocabulary: Array.from(tfidf.vocabulary),
        top_words_by_tfidf: [],
        document_features: []
    };
    
    // è®¡ç®—æ¯ä¸ªè¯çš„æ€»ä½“TF-IDFé‡è¦æ€§
    const wordImportance = {};
    tfidf.vocabulary.forEach(word => {
        let totalTFIDF = 0;
        tfidf.tfidf_matrix.forEach(docTFIDF => {
            totalTFIDF += docTFIDF[word];
        });
        wordImportance[word] = totalTFIDF;
    });
    
    // æŒ‰TF-IDFé‡è¦æ€§æ’åº
            features.top_words_by_tfidf = Object.entries(wordImportance)
            .map(([word, importance]) => ({ word, importance }))
            .sort((a, b) => b.importance - a.importance)
            .slice(0, 100); // å–å‰100ä¸ªæœ€é‡è¦çš„è¯
    
    // ä¸ºæ¯ä¸ªæ–‡æ¡£ç”Ÿæˆç‰¹å¾å‘é‡
    tfidf.documents.forEach((doc, docIndex) => {
        const featureVector = features.vocabulary.map(word => 
            tfidf.tfidf_matrix[docIndex][word]
        );
        
        features.document_features.push({
            docIndex: docIndex,
            originalText: doc.original,
            featureVector: featureVector,
            topWords: Object.entries(doc.wordFreq)
                .map(([word, freq]) => ({ word, freq }))
                .sort((a, b) => b.freq - a.freq)
                .slice(0, 10) // æ¯ä¸ªæ–‡æ¡£çš„å‰10ä¸ªè¯
        });
    });
    
    return features;
}

/**
 * åˆ†æN-Gramå’ŒTF-IDF
 */
function analyzeNGrams() {
    console.log('å¼€å§‹N-Gramå’ŒTF-IDFåˆ†æ...\n');
    
    // è¯»å–ä¿®å¤åçš„CSVæ–‡ä»¶
    const csvPath = path.join(__dirname, 'input', 'Seattle_Hotels.csv');
    const data = readCSV(csvPath);
    
    if (data.length === 0) {
        console.error('æ— æ³•è¯»å–æ•°æ®æ–‡ä»¶');
        return;
    }
    
    console.log(`ğŸ“Š è¯»å–äº† ${data.length} æ¡é…’åº—æè¿°æ•°æ®`);
    
    // åˆå¹¶æ‰€æœ‰æ–‡æœ¬ç”¨äºN-Gramåˆ†æ
    const allText = data.map(item => item.desc).join(' ');
    const cleanedText = cleanText(allText);
    const tokens = tokenize(cleanedText);
    const filteredTokens = removeStopWords(tokens);
    
    console.log(`ğŸ“ æ–‡æœ¬é¢„å¤„ç†å®Œæˆ:`);
    console.log(`   - åŸå§‹æ–‡æœ¬é•¿åº¦: ${allText.length} å­—ç¬¦`);
    console.log(`   - æ¸…ç†åæ–‡æœ¬é•¿åº¦: ${cleanedText.length} å­—ç¬¦`);
    console.log(`   - åˆ†è¯æ•°é‡: ${tokens.length} ä¸ª`);
    console.log(`   - å»åœç”¨è¯å: ${filteredTokens.length} ä¸ª`);
    
    // ç”ŸæˆN-Gram
    const unigrams = generateNGrams(filteredTokens, 1);
    const bigrams = generateNGrams(filteredTokens, 2);
    const trigrams = generateNGrams(filteredTokens, 3);
    
    // è®¡ç®—è¯é¢‘
    const unigramFreq = countFrequency(unigrams);
    const bigramFreq = countFrequency(bigrams);
    const trigramFreq = countFrequency(trigrams);
    
    // æ’åº
    const sortedUnigrams = sortByFrequency(unigramFreq);
    const sortedBigrams = sortByFrequency(bigramFreq);
    const sortedTrigrams = sortByFrequency(trigramFreq);
    
    // è®¡ç®—TF-IDF
    console.log('\nğŸ” å¼€å§‹TF-IDFç‰¹å¾æå–...');
    const tfidf = calculateTFIDF(data);
    const features = getTFIDFFeatures(tfidf);
    
    console.log(`ğŸ“ˆ TF-IDFåˆ†æå®Œæˆ:`);
    console.log(`   - è¯æ±‡è¡¨å¤§å°: ${tfidf.vocabulary.size} ä¸ªè¯`);
    console.log(`   - æ–‡æ¡£æ•°é‡: ${tfidf.documents.length} ä¸ª`);
    console.log(`   - ç‰¹å¾å‘é‡ç»´åº¦: ${features.vocabulary.length} ç»´`);
    
    // åˆ›å»ºè¾“å‡ºç›®å½•
    const outputDir = path.join(__dirname, 'output');
    if (!fs.existsSync(outputDir)) {
        fs.mkdirSync(outputDir, { recursive: true });
    }
    
    // ä¿å­˜N-Gramç»“æœ
    const wordMatrix = {
        total_words: filteredTokens.length,
        unique_words: Object.keys(unigramFreq).length,
        top_50: sortedUnigrams.slice(0, 50),
        top_15: sortedUnigrams.slice(0, 15)
    };
    
    const gram1Result = {
        total_ngrams: unigrams.length,
        top_20: sortedUnigrams.slice(0, 20)
    };
    
    const gram2Result = {
        total_ngrams: bigrams.length,
        top_20: sortedBigrams.slice(0, 20)
    };
    
    const gram3Result = {
        total_ngrams: trigrams.length,
        top_20: sortedTrigrams.slice(0, 20)
    };
    
    // ä¿å­˜TF-IDFç»“æœ
    const tfidfResult = {
        vocabulary_size: tfidf.vocabulary.size,
        document_count: tfidf.documents.length,
        top_words_by_tfidf: features.top_words_by_tfidf,
        document_features: features.document_features.map(doc => ({
            docIndex: doc.docIndex,
            topWords: doc.topWords,
            featureVectorLength: doc.featureVector.length
        })),
        sample_document_features: features.document_features.slice(0, 5).map(doc => ({
            docIndex: doc.docIndex,
            originalText: doc.originalText.substring(0, 100) + '...',
            topWords: doc.topWords,
            featureVectorSample: doc.featureVector.slice(0, 10)
        }))
    };
    
    // å†™å…¥æ–‡ä»¶
    fs.writeFileSync(path.join(outputDir, 'word_frequency_matrix.json'), JSON.stringify(wordMatrix, null, 2));
    fs.writeFileSync(path.join(outputDir, '1gram_frequency.json'), JSON.stringify(gram1Result, null, 2));
    fs.writeFileSync(path.join(outputDir, '2gram_frequency.json'), JSON.stringify(gram2Result, null, 2));
    fs.writeFileSync(path.join(outputDir, '3gram_frequency.json'), JSON.stringify(gram3Result, null, 2));
    fs.writeFileSync(path.join(outputDir, 'tfidf_features.json'), JSON.stringify(tfidfResult, null, 2));
    
    console.log('\nâœ… åˆ†æå®Œæˆï¼ç»“æœå·²ä¿å­˜åˆ°outputç›®å½•:');
    console.log(`   ğŸ“„ word_frequency_matrix.json - è¯é¢‘çŸ©é˜µ`);
    console.log(`   ğŸ“„ 1gram_frequency.json - 1-Gramåˆ†æ`);
    console.log(`   ğŸ“„ 2gram_frequency.json - 2-Gramåˆ†æ`);
    console.log(`   ğŸ“„ 3gram_frequency.json - 3-Gramåˆ†æ`);
    console.log(`   ğŸ“„ tfidf_features.json - TF-IDFç‰¹å¾æå–`);
    
    console.log('\nğŸ“Š å…³é”®ç»Ÿè®¡:');
    console.log(`   - æ€»å•è¯æ•°: ${wordMatrix.total_words}`);
    console.log(`   - å”¯ä¸€å•è¯æ•°: ${wordMatrix.unique_words}`);
    console.log(`   - 1-Gramæ€»æ•°: ${gram1Result.total_ngrams}`);
    console.log(`   - 2-Gramæ€»æ•°: ${gram2Result.total_ngrams}`);
    console.log(`   - 3-Gramæ€»æ•°: ${gram3Result.total_ngrams}`);
    console.log(`   - TF-IDFè¯æ±‡è¡¨å¤§å°: ${tfidfResult.vocabulary_size}`);
    
    console.log('\nğŸ” ä¸»è¦å‘ç°:');
    console.log(`   - æœ€å¸¸è§å•è¯: "${wordMatrix.top_50[0].item}" (${wordMatrix.top_50[0].count}æ¬¡)`);
    console.log(`   - æœ€å¸¸è§2-Gram: "${gram2Result.top_20[0].item}" (${gram2Result.top_20[0].count}æ¬¡)`);
    console.log(`   - æœ€å¸¸è§3-Gram: "${gram3Result.top_20[0].item}" (${gram3Result.top_20[0].count}æ¬¡)`);
    console.log(`   - TF-IDFæœ€é‡è¦è¯: "${features.top_words_by_tfidf[0].word}" (é‡è¦æ€§: ${features.top_words_by_tfidf[0].importance.toFixed(4)})`);
}

// è¿è¡Œåˆ†æ
analyzeNGrams();

export { cleanText, tokenize, removeStopWords, generateNGrams, countFrequency, sortByFrequency, calculateTFIDF, getTFIDFFeatures }; 